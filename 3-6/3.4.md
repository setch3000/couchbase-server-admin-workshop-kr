# 3.4 클러스터 리밸런싱

Couchbase 웹 UI에서 이제 추가 대기 중인 3개의 노드(Pending Rebalance)를 확인할 수 있습니다.

<figure><img src="../.gitbook/assets/image (69).png" alt=""><figcaption></figcaption></figure>

클러스터에는 현재 리밸런스를 기다리는 3개의 노드가 있어야 합니다.

사이드 메뉴에서 Servers 링크를 클릭하면 새로 추가된 3개의 노드가 ADD pending rebalance 상태와 각 노드에서 제공하는 서비스가 Data services임을 확인할 수 있습니다.

Couchbase에 새 노드를 추가하는 과정은 두 단계로 진행됩니다. 1단계에서는 새 노드를 추가하고, 2단계에서는 클러스터 전체에 데이터를 리밸런스합니다. 지금까지는 1단계까지만 완료된 상태입니다.

즉, 새 노드를 추가하는 것만으로는 클러스터나 데이터에 실제 변화가 생기지 않습니다. 단지 새 노드가 클러스터에 구성될 뿐입니다.

다음 단계는 클러스터 리밸런스입니다. 리밸런스 시 다음 작업이 수행됩니다:&#x20;

• vBucket이 새롭게 계산된 vBucket 맵에 맞게 노드 간 이동됩니다.&#x20;

• 리밸런스 과정에서 vBucket 맵이 업데이트되고, 모든 노드와 연결된 클라이언트에 전달됩니다.&#x20;

• 클러스터의 각 노드, 각 버킷에 대해 RAM에 있는 데이터와 디스크에 있는 데이터 모두가 이동됩니다.&#x20;

• 리밸런스 중에도 클러스터는 계속 실행되며 클라이언트 요청을 처리할 수 있습니다.&#x20;

• 클라이언트 요청을 처리할 노드를 식별하는 데 사용하는 vBucket 맵은 각 vBucket 이동 시마다 점진적으로 업데이트됩니다. \
• Couchbase SDK를 사용하는 클라이언트는 이 업데이트된 맵을 실시간으로 받아 최신 상태로 동작할 수 있습니다.

\
리밸런스를 수행하는 주요 이유는 네 가지입니다: \
1\. 클러스터 규모를 확장하기 위해 노드 추가 \
2\. 클러스터 규모를 축소하기 위해 노드 제거 \
3\. 장애 복구를 통해 클러스터를 정상 상태로 복원 \
4\. 소프트웨어, OS, 하드웨어 업그레이드를 위해 노드를 일시적으로 제거\


## 1. 리밸런스 전 활성/복제 vBucket 수 확인

리밸런스 작업을 시작하기 전에 cbstats 명령을 실행하고, beer-sample 버킷에 대해 active\_num과 replica\_num 변수를 grep으로 검색하여 첫 번째 노드가 해당 버킷의 모든 1024개의 vBucket을 담당하고 있는지 확인합니다.

이 명령은 클러스터의 첫 번째 노드(짙은 파란색 Couchbase01)에서, 첫 번째 노드의 퍼블릭 호스트 이름을 사용해 실행해야 합니다.

```
[ec2-user@couchbase01 ~]$ cbstats $NODE1:11210 all -u Administrator -p couchbase -b beer-sample | grep active_num
```

출력:

```
vb_active_num:                                         1024
vb_active_num_non_resident:                            0
```



복제본(Replica) 통계를 확인하려면 다음을 실행합니다:

```
[ec2-user@couchbase01 ~]$ cbstats $NODE1:11210 all -u Administrator -p couchbase -b beer-sample | grep replica_num
```



출력:

```
vb_active_num:                                         0
vb_active_num_non_resident:                            0
```



## 2. 리밸런스 수행

`Rebalance` 버튼을 클릭합니다.

<figure><img src="../.gitbook/assets/image (70).png" alt=""><figcaption></figcaption></figure>



웹 UI에서 리밸런스 진행 상황을 모니터링할 수 있습니다. 이 과정에서 일부 서버(특히 모든 데이터가 있는 첫 번째 VM)의 CPU 사용량이 높아지는 것을 볼 수 있습니다.

첫 번째 노드의 IP 주소 영역을 클릭해 해당 노드의 자세한 통계를 확인해 보십시오.

<figure><img src="../.gitbook/assets/image (71).png" alt=""><figcaption></figcaption></figure>

여기에는 두 개의 주요 섹션이 있습니다:\
• 데이터 전송(Out)\
• 데이터 수신(In)

위 샘플 스크린샷에서는 첫 번째 노드에서 다른 노드로 샘플 버킷이 전송되고 있습니다. 첫 번째 노드로 전송되는 데이터는 없습니다.\
gamesim-sample 버킷의 리밸런스가 끝나면, 노드들은 beer-sample 버킷, 그 다음 default 버킷, 마지막으로 travel-sample 버킷 순으로 리밸런스를 진행합니다.

**`전체 리밸런스 과정은 몇 분 정도 소요됩니다.`**

리밸런스가 진행되는 동안 cbstats 도구를 사용해 리밸런스 통계를 확인할 수도 있습니다.



{% hint style="info" %}
다음 명령어들은 beer-sample 버킷이 리밸런스 중일 때만 실행해야 합니다! 위의 웹 UI에서 반드시 이를 확인하십시오.
{% endhint %}

`beer-sample` 데이터베이스가 리밸런스를 시작할 때까지 기다리십시오. 첫 번째 노드의 세부 정보에서 Data being transferred out 섹션을 확인하여 리밸런스 작업이 beer-sample 버킷에서 실행 중인지 검증할 수 있습니다.

<figure><img src="../.gitbook/assets/image (72).png" alt=""><figcaption></figcaption></figure>



## 3. 실행 중 리밸런스 프로세스 모니터링

beer-sample 버킷이 리밸런스 중일 때(약 2분 소요) 아래 단계들(3.1부터 3.3까지)을 신속히 실행하십시오!\
beer-sample 버킷의 리밸런스가 완료된 후에는 아래 명령들의 출력 결과가 동일하지 않을 것입니다.



### 3.1 DCP 백필(Backfill) 통계 가져오기

3.1 첫 번째 노드(Couchbase01)의 `PuTTY 셸(짙은 파란색 창)`로 이동하여 다음을 실행합니다:

```
[ec2-user@Couchbase01 ~]$ cd ~
```

다음 명령은 DCP 백필(Backfill) 프로세스 목록과 각 프로세스가 아직 실행 중(true)인지 완료(false)되었는지를 반환합니다.

DCP 프로토콜은 Couchbase Server 시스템의 내부 구성 요소로, 시스템 전반에 걸쳐 데이터를 교환하는 여러 영역에서 사용됩니다. DCP는 시스템 내에서 발생하는 변경 사항의 데이터 스트림을 제공합니다.

DCP는 복제(Replication) 시 복제본에 사용되는 vBucket 간 데이터 복사에 사용되며, 또한 리밸런스 과정에서도 vBucket 간 데이터를 이동시키고 시스템 전반에 걸쳐 정보를 재분배하는 데 사용됩니다.

**다음 명령은 첫 번째 노드의 퍼블릭 호스트 이름을 사용하여 실행합니다:**



```
[ec2-user@Couchbase01 ~]$ cbstats $NODE1:11210 dcp -u Administrator -p couchbase -b beer-sample | grep backfill
```

```
ep_dcp_max_running_backfills:                                        102
ep_dcp_num_running_backfills:                                        0
ep_dcp_queue_backfillremaining:                                      0
eq_dcpq:mapreduce_view: beer-sample _design/beer (prod/main :backfill_buffer_bytes_read:  0
eq_dcpq:mapreduce_view: beer-sample _design/beer (prod/main):backfill_buffer_full:        false
eq_dcpq:mapreduce_view: beer-sample _design/beer (prod/main):backfill_buffer_max_bytes:   20971832
eq_dcpq:mapreduce_view: beer-sample _design/beer (prod/main):backfill_num_active:         0
eq_dcpq:mapreduce_view: beer-sample _design/beer (prod/main):backfill_num_pending:        0
eq_dcpq:mapreduce_view: beer-sample _design/beer (prod/main):backfill_num_snoozing:       0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-173-46-5.compute-1.amazonaws.com:beer-sample backfill_buffer_bytes_read:   0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-173-46-5.compute-1.amazonaws.com:beer-sample backfill_buffer_full:         false
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-173-46-5.compute-1.amazonaws.com:beer-sample backfill_buffer_max_bytes:    20971832
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-173-46-5.compute-1.amazonaws.com:beer-sample backfill_num_active:          0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-173-46-5.compute-1.amazonaws.com:beer-sample backfill_num_pending:         0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-173-46-5.compute-1.amazonaws.com:beer-sample backfill_num_snoozing:        0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-174-67-95.compute-1.amazonaws.com:beer-sample:backfill_buffer_bytes_read:  0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-174-67-95.compute-1.amazonaws.com:beer-sample:backfill_buffer_full:        false
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-174-67-95.compute-1.amazonaws.com:beer-sample:backfill_buffer_max_bytes:   20971832
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-174-67-95.compute-1.amazonaws.com:beer-sample:backfill_num_active:         0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-174-67-95.compute-1.amazonaws.com:beer-sample:backfill_num_pending:        0
eq_dcpq:replication:ns_1@ec2-54-174-65-105.compute-1.amazonaws.com->ns_1@ec2-54-174-67-95.compute-1.amazonaws.com:beer-sample:backfill_num_snoozin         0

```

위 명령의 출력에서 DCP 큐의 백필(Backfill) 상태를 확인합니다.



## 3.2 리밸런스 중 UI에서 DCP 통계를 모니터링합니다.

beer-sample 버킷에서 리밸런스가 진행되는 동안(이 시점에서 전체 버킷의 리밸런스는 전체 노드 기준 약 50% 정도 완료되었을 것입니다), Server Nodes 아래에서 첫 번째 VM의 서버 이름을 클릭하여 리밸런스 중 첫 번째 노드의 상세 통계를 확인합니다.

<figure><img src="../.gitbook/assets/image (73).png" alt=""><figcaption></figcaption></figure>



왼쪽 메뉴의 Dashboard 링크에서 beer-sample 버킷으로 전환하고, 두 번째 드롭다운을 All Server Nodes로 변경합니다.

<figure><img src="../.gitbook/assets/image (74).png" alt=""><figcaption></figcaption></figure>



왼쪽 상단의 드롭다운에서 All Services를 선택합니다.

<figure><img src="../.gitbook/assets/image (75).png" alt=""><figcaption></figcaption></figure>



아래로 스크롤한 후 vBucket resources를 확장합니다.

<figure><img src="../.gitbook/assets/image (76).png" alt=""><figcaption></figcaption></figure>



아래로 스크롤하여 `DCP Queues` 도 확인합니다.

<figure><img src="../.gitbook/assets/image (77).png" alt=""><figcaption></figcaption></figure>



위 스크린샷에서 replications 열에 8개의 DCP 연결이 있으며, 각 서버의 DCP sender가 4개씩 있음을 확인할 수 있습니다. 또한 drain rate도 볼 수 있습니다. 마우스를 작은 그래프 위에 올리면 그래프가 의미하는 바를 더 자세히 확인할 수 있습니다.

Couchbase의 클러스터 내 통신은 DCP에 의해 처리되며, 여기서 DCP 관련 통계도 확인할 수 있습니다.

이 그래프와 차트가 의미하는 더 자세한 내용은 추후 수업의 **성능 실습(performance lab)**&#xC5D0;서 다룰 예정입니다.

기본적으로 beer-sample 버킷에는 **1개의 복제본(replica)**&#xC774; 구성되어 있어, 모든 키/값 쌍이 복제됩니다. 이 설정은 GUI 상단 메뉴에서 `Data Buckets`을 클릭하고 beer-sample을 확장하여 확인할 수 있습니다.

<figure><img src="../.gitbook/assets/image (78).png" alt=""><figcaption></figcaption></figure>



## 3.3 활성/복제 vBucket 수 확인

\
beer-sample 버킷이 리밸런스되는 동안, 첫 번째(짙은 파란색) 노드에서 첫 번째 노드의 퍼블릭 호스트 이름을 사용해 다음 명령을 다시 실행하면, 이 노드의 활성 vBucket 수가 기존 1024개에서 더 낮은 숫자로 줄어드는 것을 확인할 수 있습니다. (감소 폭은 리밸런스 진행 상황에 따라 다릅니다)

```
[ec2-user@couchbase01 ~]$ cbstats $NODE1:11210 all -u Administrator -p couchbase -b beer-sample | grep active_num
```

```
vb_active_num:                                         1024
vb_active_num_non_resident:                            0
```

```
[ec2-user@couchbase01 ~]$ cbstats $NODE1:11210 all -u Administrator -p couchbase -b beer-sample | grep replica_num
```

```
vb_replica_num:                                        0
vb_replica_num_non_resident:                           0
```

beer-sample 버킷의 리밸런스가 완료되면, 동일한 명령을 실행했을 때 첫 번째 노드에서 256개의 활성 vBucket과 256개의 복제 vBucket이 표시됩니다.

```
[ec2-user@ Couchbase01 ~]$ cbstats $NODE1:11210 all -u Administrator -p couchbase -b beer-sample | grep active_num
```

```
vb_active_num:                      256
vb_active_num_non_resident:         0
```

```
[ec2-user@couchbase01 ~]$ cbstats $NODE1:11210 all -u Administrator -p couchbase -b beer-sample | grep replica_num
```

```
vb_replica_num:                     256
vb_replica_num_non_resident:        0
```







## 4. 리밸런스 후: 활성/복제 vBucket 파일 수 확인

기본(default) 버킷에 대한 리밸런스가 아직 진행 중일 수 있습니다. 기본 버킷의 리밸런스가 완료되면, 첫 번째 노드에서 총 256개의 활성 vBucket이 표시되지만, 복제 vBucket은 0으로 표시됩니다. (기본 버킷에는 복제본이 구성되어 있지 않기 때문입니다)



```
[ec2-user@ Couchbase01 ~]$ cbstats $NODE1:11210 all -b default -u Administrator -p couchbase | egrep  replica_num
```

```
vb_replica_num:                     0
vb_replica_num_non_resident:        0
```



4개의 노드와 3개의 버킷에 대한 전체 리밸런스 작업이 완료되면, Server Nodes 화면이 다음과 같이 새로 고침됩니다:

<figure><img src="../.gitbook/assets/image (79).png" alt=""><figcaption></figcaption></figure>

`cbstats` 명령에 대한 전체 세부 정보는 다음 링크에서 확인할 수 있습니다:\
https://docs.couchbase.com/server/current/cli/cbstats-intro.html

Couchbase에서 리밸런스 기술이 작동하는 방식에 대한 자세한 내용은 아래 두 개의 블로그 글을 참조하십시오:\
• http://blog.couchbase.com/rebalancing-couchbase-part-i\
• http://blog.couchbase.com/rebalancing-couchbase-part-ii

일반적으로 리밸런스 작업이 실행되는 동안 애플리케이션의 가용성에는 영향이 없어야 합니다.

이 실습에서 사용하는 명령은 Linux에서 beer-sample 버킷의 데이터 디렉터리에 있는 파일 수를 계산합니다. 이 명령은 첫 번째 노드(짙은 파란색)에서 실행합니다.

```
[ec2-user@Couchbase01 ~]$ sudo ls -al /opt/couchbase/var/lib/couchbase/data/beer-sample | wc -l

# Output:
518
```



명령 출력에 따르면 이 디렉토리에는 518개의 파일이 있습니다. 각 버킷에는 총 1024개의 vBucket/파티션이 있으므로, 4노드 클러스터에서는 각 노드가 약 256개의 vBucket을 보유하게 됩니다.

따라서 첫 번째 노드에서 beer-sample 버킷의 경우:\
• 활성 vBucket용 파일: 256개\
• 복제 vBucket용 파일: 256개\
• 몇 개의 추가 메타데이터 파일\
• 총합: 약 518개

기본 버킷(default bucket)의 경우 복제본이 0으로 설정되어 있으므로 첫 번째 노드에는 약 256개의 파일만 존재하게 됩니다.

```
[ec2-user@ Couchbase01 ~]$ sudo ls -al /opt/couchbase/var/lib/couchbase/data/default | wc -l

# Output:
270
```



## 5. 클러스터 이름 변경&#x20;

이제 Settings 탭으로 이동하여 클러스터 이름을 `4 Node Cluster`로 변경합니다.

<figure><img src="../.gitbook/assets/image (80).png" alt=""><figcaption></figcaption></figure>

`Save`를 클릭합니다.

